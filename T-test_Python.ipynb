{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test example with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A math teacher was curious about the effect of the amount of homework on students' performance. Therefore, she gave homework to Class A more often but rarely to Class B. Then she recorded, the Math exam grades of the two classes. The data is shown below.    \n",
    "\n",
    "class_a = [80.4, 85. , 71. , 73.6, 69.4, 91.1, 87.9, 90.1, 83.7, 84.5, 74.6, 88.8, 74.8, 76.9, 78.3, 76.4, 84. , 78.9, 79.7, 79. , 86.2]      \n",
    "class_b = [72.3, 74.9, 78.6, 66. , 73.1, 79.3, 83.1, 77. , 71.9, 84.8, 74.6,76.2, 77.1, 75.6, 72.7, 78.9, 68.9]\n",
    "\n",
    "**Conduct the hypothesis testing to check whether there is a difference between the average grades by using a 0.05 significance level to evaluate the null and alternative hypotheses. Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have samples which are having unequal sample sizes so we can use t-test is a nonparametric univariate test that tests for a significant difference between the mean of two unrelated groups. It is an alternative to the independent t-test when there is a violation in the assumption of equality of variances.\n",
    "\n",
    "The hypothesis being tested is:\n",
    "\n",
    "Null hypothesis (H0): u1 = u2, which translates to the mean of class_a is equal to the mean of class_two Alternative hypothesis (HA): u1 ≠ u2, which translates to the mean of class_a is not equal to the mean of class_b If the p-value is less than what is tested at, 0.05, one can reject the null hypothesis.\n",
    "\n",
    "In first Step for assumptions check: We can test the assumptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=2.297939000889231, pvalue=0.13827820173533892)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_a = [80.4, 85. , 71. , 73.6, 69.4, 91.1, 87.9, 90.1, 83.7, 84.5, 74.6, 88.8, 74.8, 76.9, 78.3, 76.4, 84. , 78.9, 79.7, 79. , 86.2]\n",
    "class_b = [72.3, 74.9, 78.6, 66. , 73.1, 79.3, 83.1, 77. , 71.9, 84.8, 74.6,76.2, 77.1, 75.6, 72.7, 78.9, 68.9]\n",
    "\n",
    "#homogeneity check\n",
    "stats.levene(class_a, class_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test is not significant meaning there is homogeneity of variances and we can proceed. Also, we can assume that we have equal variences thus samples sizes does not effect to choosing test. we can use t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9706092476844788, pvalue=0.7464964389801025)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_a = [80.4, 85. , 71. , 73.6, 69.4, 91.1, 87.9, 90.1, 83.7, 84.5, 74.6, 88.8, 74.8, 76.9, 78.3, 76.4, 84. , 78.9, 79.7, 79. , 86.2]\n",
    "class_b = [72.3, 74.9, 78.6, 66. , 73.1, 79.3, 83.1, 77. , 71.9, 84.8, 74.6,76.2, 77.1, 75.6, 72.7, 78.9, 68.9]\n",
    "\n",
    "#normality check\n",
    "stats.shapiro(class_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After shapiro tests P values are greater than. 0.05 thus we can agree say we cannot reject normality our data. We can assume that our both data normal. To conduct a t-test, one needs to use the stats.ttest_ind() method while passing “False” in the “equal_var=” argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.769081816460252, pvalue=0.008829413211847987)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(class_a, class_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is significant, therefore one can reject the null hypothesis in support of the alternative. t this significance level, there is enough evidence to conclude that the average grade of Class A is different than the Class B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
